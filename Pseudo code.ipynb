{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import *\n",
    "import pandas as pd \n",
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packet = rdpcap('home/downloads/dataset/26.09.14/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract attributes | (Facing Problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract attributes from packet {flow volume, flow duration, flow rate, sleep time, DNS interval, NTP interval}\n",
    "extract remote port numbers\n",
    "extract domain names\n",
    "extract cipher suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file):\n",
    "    Payloads = []\n",
    "    with PcapReader(file) as pr:\n",
    "        for packet in pr:        \n",
    "            Payloads.append(str(packet[TCP].payload))\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(Payloads)\n",
    "\n",
    "\n",
    "    Data = []\n",
    "    for payload in Payloads:\n",
    "        payload = re.sub(r'[^a-zA-Z0-9.\\s]', ' ', payload)\n",
    "        payload = [payload]\n",
    "        sequences = tokenizer.texts_to_sequences(payload)\n",
    "        Data.append(preprocessing.sequence.pad_sequences(sequences, maxlen = 200)[0])\n",
    "    return Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = preprocess_data(packet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes multinomial classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bag of words \n",
    "cv = CountVectorizer(max_features = 1500) \n",
    "\n",
    "X = cv.fit_transform(corpus).toarray() \n",
    "y = dataset.iloc[:, 1].values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting naive bayes to the training set \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "classifier = GaussianNB(); \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "# predicting test set results \n",
    "y_pred = classifier.predict(X_test) \n",
    "\n",
    "# making the confusion matrix \n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "cm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display using graphs and arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integrating UI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
